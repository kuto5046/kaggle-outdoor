{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 100)\n",
    "import scipy.optimize as opt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import multiprocessing\n",
    "from pathlib import Path\n",
    "import pathlib\n",
    "from tqdm.notebook import tqdm\n",
    "INPUT = '../input/google-smartphone-decimeter-challenge/'\n",
    "root = Path(INPUT)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def ecef2lla(x, y, z):\n",
    "    # x, y and z are scalars or vectors in meters\n",
    "    x = np.array([x]).reshape(np.array([x]).shape[-1], 1)\n",
    "    y = np.array([y]).reshape(np.array([y]).shape[-1], 1)\n",
    "    z = np.array([z]).reshape(np.array([z]).shape[-1], 1)\n",
    "\n",
    "    a=6378137\n",
    "    a_sq=a**2\n",
    "    e = 8.181919084261345e-2\n",
    "    e_sq = 6.69437999014e-3\n",
    "\n",
    "    f = 1/298.257223563\n",
    "    b = a*(1-f)\n",
    "\n",
    "    # calculations:\n",
    "    r = np.sqrt(x**2 + y**2)\n",
    "    ep_sq  = (a**2-b**2)/b**2\n",
    "    ee = (a**2-b**2)\n",
    "    f = (54*b**2)*(z**2)\n",
    "    g = r**2 + (1 - e_sq)*(z**2) - e_sq*ee*2\n",
    "    c = (e_sq**2)*f*r**2/(g**3)\n",
    "    s = (1 + c + np.sqrt(c**2 + 2*c))**(1/3.)\n",
    "    p = f/(3.*(g**2)*(s + (1./s) + 1)**2)\n",
    "    q = np.sqrt(1 + 2*p*e_sq**2)\n",
    "    r_0 = -(p*e_sq*r)/(1+q) + np.sqrt(0.5*(a**2)*(1+(1./q)) - p*(z**2)*(1-e_sq)/(q*(1+q)) - 0.5*p*(r**2))\n",
    "    u = np.sqrt((r - e_sq*r_0)**2 + z**2)\n",
    "    v = np.sqrt((r - e_sq*r_0)**2 + (1 - e_sq)*z**2)\n",
    "    z_0 = (b**2)*z/(a*v)\n",
    "    h = u*(1 - b**2/(a*v))\n",
    "    phi = np.arctan((z + ep_sq*z_0)/r)\n",
    "    lambd = np.arctan2(y, x)\n",
    "\n",
    "    return phi*180/np.pi, lambd*180/np.pi, h\n",
    "\n",
    "def calc_haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Calculates the great circle distance between two points\n",
    "    on the earth. Inputs are array-like and specified in decimal degrees.\n",
    "    \"\"\"\n",
    "    RADIUS = 6_367_000\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + \\\n",
    "      np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    dist = 2 * RADIUS * np.arcsin(a**0.5)\n",
    "    return dist"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def make_gt(recal):\n",
    "    if recal:\n",
    "        p = pathlib.Path(INPUT)\n",
    "        gt_files = list(p.glob('train/*/*/ground_truth.csv'))\n",
    "        print('ground_truth.csv count : ', len(gt_files))\n",
    "\n",
    "        gts = []\n",
    "        for gt_file in tqdm(gt_files):\n",
    "            gts.append(pd.read_csv(gt_file))\n",
    "        ground_truth = pd.concat(gts)\n",
    "        ground_truth.to_csv(root / 'gt.csv',index=False)\n",
    "    else:\n",
    "        ground_truth = pd.read_csv(root / 'gt.csv')\n",
    "    return ground_truth\n",
    "    \n",
    "gt = make_gt(recal=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ground_truth.csv count :  73\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/73 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f9b926c0808742089d5334e8c8bf248b"
      }
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def percentile50(x):\n",
    "    return np.percentile(x, 50)\n",
    "def percentile95(x):\n",
    "    return np.percentile(x, 95)\n",
    "\n",
    "def get_train_score(df, gt):\n",
    "    gt = gt.rename(columns={'latDeg':'latDeg_gt', 'lngDeg':'lngDeg_gt'})\n",
    "    df = df.merge(gt, on=['collectionName', 'phoneName', 'millisSinceGpsEpoch'], how='inner')\n",
    "    # calc_distance_error\n",
    "    df['err'] = calc_haversine(df['latDeg_gt'], df['lngDeg_gt'], df['latDeg'], df['lngDeg'])\n",
    "    # calc_evaluate_score\n",
    "    df['phone'] = df['collectionName'] + '_' + df['phoneName']\n",
    "    res = df.groupby('phone')['err'].agg([percentile50, percentile95])\n",
    "    res['p50_p90_mean'] = (res['percentile50'] + res['percentile95']) / 2 \n",
    "    score = res['p50_p90_mean'].mean()\n",
    "    return score\n",
    "\n",
    "def get_train_score_df(df, gt):\n",
    "    gt = gt.rename(columns={'latDeg':'latDeg_gt', 'lngDeg':'lngDeg_gt'})\n",
    "    df = df.merge(gt, on=['collectionName', 'phoneName', 'millisSinceGpsEpoch'], how='left')\n",
    "    # calc_distance_error\n",
    "    df['err'] = calc_haversine(df['latDeg_gt'], df['lngDeg_gt'], df['latDeg'], df['lngDeg'])\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def gnss_log_to_dataframes(path):\n",
    "    '''Load GNSS Log'''\n",
    "    print('Loading ' + path, flush = True)\n",
    "    gnss_section_names = {'Raw', 'UncalAccel', 'UncalGyro', 'UncalMag', 'Fix', 'Status', 'OrientationDeg'}\n",
    "    with open(path) as f_open:\n",
    "        datalines = f_open.readlines()\n",
    "\n",
    "    datas = {k: [] for k in gnss_section_names}\n",
    "    gnss_map = {k: [] for k in gnss_section_names}\n",
    "    for dataline in datalines:\n",
    "        is_header = dataline.startswith('#')\n",
    "        dataline = dataline.strip('#').strip().split(',')\n",
    "        # skip over notes, version numbers, etc\n",
    "        if is_header and dataline[0] in gnss_section_names:\n",
    "            gnss_map[dataline[0]] = dataline[1:]\n",
    "        elif not is_header:\n",
    "            datas[dataline[0]].append(dataline[1:])\n",
    "\n",
    "    results = dict()\n",
    "    for k, v in datas.items():\n",
    "        results[k] = pd.DataFrame(v, columns=gnss_map[k])\n",
    "    # pandas doesn't properly infer types from these lists by default\n",
    "    for k, df in results.items():\n",
    "        for col in df.columns:\n",
    "            if col == 'CodeType':\n",
    "                continue\n",
    "            results[k][col] = pd.to_numeric(results[k][col])\n",
    "\n",
    "    return results"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# apply tips1\n",
    "# _derivedのmillisSinceGpsEpochが次のepoch(rawの)を示しているので元に戻す\n",
    "def apply_tips1(raw_df, derived_df):\n",
    "    # Create a new column in df_raw that corresponds to derivedの['millisSinceGpsEpoch']\n",
    "    raw_df['millisSinceGpsEpoch'] = np.floor((raw_df['TimeNanos'] - raw_df['FullBiasNanos']) / 1000000.0).astype(int)\n",
    "        \n",
    "    # Change each value in df_derived['MillisSinceGpsEpoch'] to be the prior epoch.\n",
    "    raw_timestamps = raw_df['millisSinceGpsEpoch'].unique()\n",
    "    derived_timestamps = derived_df['millisSinceGpsEpoch'].unique()\n",
    "\n",
    "    # The timestamps in derived are one epoch ahead. We need to map each epoch\n",
    "    # in derived to the prior one (in Raw).\n",
    "    indexes = np.searchsorted(raw_timestamps, derived_timestamps)\n",
    "    from_t_to_fix_derived = dict(zip(derived_timestamps, raw_timestamps[indexes-1]))\n",
    "    derived_df['millisSinceGpsEpoch'] = np.array(list(map(lambda v: from_t_to_fix_derived[v], derived_df['millisSinceGpsEpoch'])))\n",
    "    return derived_df\n",
    "\n",
    "# apply tips5\n",
    "# derivedの重複している行を削除\n",
    "def apply_tips5(derived_df):\n",
    "    delta_millis = derived_df['millisSinceGpsEpoch'] - derived_df['receivedSvTimeInGpsNanos'] / 1e6\n",
    "    where_good_signals = (delta_millis > 0) & (delta_millis < 300)\n",
    "    return derived_df[where_good_signals]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "output_dir = '../input/derived/'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# def estimate_train_position_by_derived(args):\n",
    "#     (collection_name, phone_name), base_df = args\n",
    "#     if \"SJC\" not in collection_name:\n",
    "#         return base_df\n",
    "#     # Train df here only contains one collection and one measurement\n",
    "#     derived_df = pd.read_csv(root / f\"train/{collection_name}/{phone_name}/{phone_name}_derived.csv\")\n",
    "#     gnss_df = gnss_log_to_dataframes(str(root / f\"train/{collection_name}/{phone_name}/{phone_name}_GnssLog.txt\"))\n",
    "#     raw_df = gnss_df['Raw']\n",
    "\n",
    "#     # epochを合わせる\n",
    "#     derived_df = apply_tips1(raw_df, derived_df)\n",
    "#     derived_df = apply_tips5(derived_df)\n",
    "#     derived_df = derived_df.sort_values('millisSinceGpsEpoch')\n",
    "    \n",
    "#     # pseudorangeの修正\n",
    "#     derived_df['correctedPrM'] = derived_df.apply(lambda r: r.rawPrM + r.satClkBiasM - r.isrbM - r.ionoDelayM - r.tropoDelayM,axis=1)\n",
    "    \n",
    "#     # 伝播時間=擬似距離/光速\n",
    "#     # 受信時刻と送信時刻の差分となる\n",
    "#     light_speed = 299_792_458\n",
    "#     derived_df['transmissionTimeSeconds'] = derived_df['correctedPrM'] / light_speed\n",
    "\n",
    "#     # Compute true sat positions at arrival time\n",
    "#     # 到着までに衛星位置が移動しているのでこれを補正\n",
    "#     omega_e = 7.2921151467e-5\n",
    "#     derived_df['xSatPosMRotated'] = \\\n",
    "#         np.cos(omega_e * derived_df['transmissionTimeSeconds']) * derived_df['xSatPosM'] \\\n",
    "#         + np.sin(omega_e * derived_df['transmissionTimeSeconds']) * derived_df['ySatPosM']\n",
    "\n",
    "#     derived_df['ySatPosMRotated'] = \\\n",
    "#         - np.sin(omega_e * derived_df['transmissionTimeSeconds']) * derived_df['xSatPosM'] \\\n",
    "#         + np.cos(omega_e * derived_df['transmissionTimeSeconds']) * derived_df['ySatPosM']\n",
    "\n",
    "#     derived_df['zSatPosMRotated'] = derived_df['zSatPosM']\n",
    "\n",
    "#     derived_df['uncertaintyWeight'] = 1 / derived_df['rawPrUncM']\n",
    "\n",
    "#     output_df = pd.DataFrame()\n",
    "#     d_list = []\n",
    "#     x_list = []\n",
    "#     y_list = []\n",
    "#     z_list = []\n",
    "#     epoch_list = []\n",
    "#     for epoch, df in derived_df.groupby('millisSinceGpsEpoch'): \n",
    "#         # Corrected pseudorange according to data instructions\n",
    "#         # Time it took for signal to travel\n",
    "#         # Start point for the optimiser\n",
    "\n",
    "#         print(df[\"signalType\"].unique())\n",
    "\n",
    "#         # if df[\"signalType\"] == \"GPS_L1\":\n",
    "#         break\n",
    "#         # 最小2乗法による座標の推定\n",
    "#         # GPS_L1のみの場合、状態数=4\n",
    "#         x0 = [0,0,0,0]  # x,y,z,prm\n",
    "#         opt_res = opt.least_squares(distance, x0, \n",
    "#         args=(\n",
    "#             df['xSatPosMRotated'].values, \n",
    "#             df['ySatPosMRotated'].values, \n",
    "#             df['zSatPosMRotated'].values,\n",
    "#             df['correctedPrM'].values,\n",
    "#             df['isrbM'].values,\n",
    "#             df['uncertaintyWeight'].values))\n",
    "\n",
    "#         # Optimiser yields a position in the ECEF coordinates\n",
    "#         opt_res_pos = opt_res.x\n",
    "#         d = distance(\n",
    "#             opt_res_pos, \n",
    "#             df['xSatPosMRotated'], \n",
    "#             df['ySatPosMRotated'], \n",
    "#             df['zSatPosMRotated'], \n",
    "#             df['correctedPrM'], \n",
    "#             df[\"isrbM\"],\n",
    "#             df['uncertaintyWeight']\n",
    "#             )\n",
    "\n",
    "#         # ECEF position to lat/long\n",
    "#         wls_estimated_pos = ecef2lla(*opt_res_pos[:3])\n",
    "#         wls_estimated_pos = np.squeeze(wls_estimated_pos)\n",
    "#         d_list.append(d)\n",
    "#         x_list.append(wls_estimated_pos[0])\n",
    "#         y_list.append(wls_estimated_pos[1])\n",
    "#         z_list.append(wls_estimated_pos[2])\n",
    "#         epoch_list.append(epoch)\n",
    "\n",
    "#     output_df[\"latDeg\"] = x_list\n",
    "#     output_df[\"lngDeg\"] = y_list\n",
    "#     output_df['heightAboveWgs84EllipsoidM'] = z_list\n",
    "#     output_df[\"dist\"] = d_list\n",
    "#     output_df['millisSinceGpsEpoch'] = epoch_list\n",
    "#     output_df['collectionName'] = collection_name\n",
    "#     output_df['phoneName'] = phone_name\n",
    "\n",
    "#     output_df.to_csv(output_dir + f'{collection_name}_{phone_name}_derived.csv', index=False)\n",
    "#     return output_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "base_train = pd.read_csv(root/ 'baseline_locations_train.csv')\n",
    "base_train.loc[:,['px','py','pz']] = 0\n",
    "base_train.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        collectionName phoneName  millisSinceGpsEpoch     latDeg      lngDeg  \\\n",
       "0  2020-05-14-US-MTV-1    Pixel4        1273529463442  37.423575 -122.094091   \n",
       "1  2020-05-14-US-MTV-1    Pixel4        1273529464442  37.423578 -122.094101   \n",
       "2  2020-05-14-US-MTV-1    Pixel4        1273529465442  37.423573 -122.094111   \n",
       "3  2020-05-14-US-MTV-1    Pixel4        1273529466442  37.423583 -122.094121   \n",
       "4  2020-05-14-US-MTV-1    Pixel4        1273529467442  37.423579 -122.094114   \n",
       "\n",
       "   heightAboveWgs84EllipsoidM                       phone  px  py  pz  \n",
       "0                      -34.06  2020-05-14-US-MTV-1_Pixel4   0   0   0  \n",
       "1                      -33.29  2020-05-14-US-MTV-1_Pixel4   0   0   0  \n",
       "2                      -30.99  2020-05-14-US-MTV-1_Pixel4   0   0   0  \n",
       "3                      -32.83  2020-05-14-US-MTV-1_Pixel4   0   0   0  \n",
       "4                      -34.49  2020-05-14-US-MTV-1_Pixel4   0   0   0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>collectionName</th>\n      <th>phoneName</th>\n      <th>millisSinceGpsEpoch</th>\n      <th>latDeg</th>\n      <th>lngDeg</th>\n      <th>heightAboveWgs84EllipsoidM</th>\n      <th>phone</th>\n      <th>px</th>\n      <th>py</th>\n      <th>pz</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-05-14-US-MTV-1</td>\n      <td>Pixel4</td>\n      <td>1273529463442</td>\n      <td>37.423575</td>\n      <td>-122.094091</td>\n      <td>-34.06</td>\n      <td>2020-05-14-US-MTV-1_Pixel4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-05-14-US-MTV-1</td>\n      <td>Pixel4</td>\n      <td>1273529464442</td>\n      <td>37.423578</td>\n      <td>-122.094101</td>\n      <td>-33.29</td>\n      <td>2020-05-14-US-MTV-1_Pixel4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-05-14-US-MTV-1</td>\n      <td>Pixel4</td>\n      <td>1273529465442</td>\n      <td>37.423573</td>\n      <td>-122.094111</td>\n      <td>-30.99</td>\n      <td>2020-05-14-US-MTV-1_Pixel4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-05-14-US-MTV-1</td>\n      <td>Pixel4</td>\n      <td>1273529466442</td>\n      <td>37.423583</td>\n      <td>-122.094121</td>\n      <td>-32.83</td>\n      <td>2020-05-14-US-MTV-1_Pixel4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-05-14-US-MTV-1</td>\n      <td>Pixel4</td>\n      <td>1273529467442</td>\n      <td>37.423579</td>\n      <td>-122.094114</td>\n      <td>-34.49</td>\n      <td>2020-05-14-US-MTV-1_Pixel4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# kwargsはdict\n",
    "def distance(x, **kwargs):\n",
    "    weight = kwargs[\"uncertaintyWeight\"]\n",
    "    prm = kwargs[\"correctedPrM\"]\n",
    "    \n",
    "    satx = kwargs['xSatPosMRotated'] - x[0]\n",
    "    saty = kwargs['ySatPosMRotated'] - x[1]\n",
    "    satz = kwargs['zSatPosMRotated'] - x[2]\n",
    "\n",
    "    d = weight * (np.sqrt((satx**2 + saty**2 +satz**2)) + x[3] - prm)\n",
    "    return d\n",
    "\n",
    "# Set up least squares methods\n",
    "# def distance(x, **kwargs):\n",
    "#     satx = kwargs[\"xSatPosMRotated\"] - x[0]\n",
    "#     saty = kwargs[\"ySatPosMRotated\"] - x[1]\n",
    "#     satz = kwargs[\"zSatPosMRotated\"] - x[2]\n",
    "#     weight = kwargs[\"uncertaintyWeight\"]\n",
    "#     prm = kwargs[\"correctedPrM\"]\n",
    "#     isrbm = kwargs[\"isrbM\"]\n",
    "#     isrbms = [k for k in kwargs.keys() if \"_isrbM\" in k]\n",
    "#     N = len(isrbms)\n",
    "#     isrbms_loss = 0\n",
    "#     for i in range(N):\n",
    "#         isrbms_loss += x[4+i] - kwargs[isrbms[i]]\n",
    "\n",
    "#         isrbms_loss += x[4+i]\n",
    "\n",
    "#     d = weight * (np.sqrt(satx**2 + saty**2 +satz**2) + x[3] - prm + isrbm)\n",
    "#     return d\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_train_position_by_derived(args):\n",
    "    (collection_name, phone_name), base_df = args\n",
    "    if \"SJC\" not in collection_name:\n",
    "        return base_df\n",
    "    # Train df here only contains one collection and one measurement\n",
    "    derived_df = pd.read_csv(root / f\"train/{collection_name}/{phone_name}/{phone_name}_derived.csv\")\n",
    "    gnss_df = gnss_log_to_dataframes(str(root / f\"train/{collection_name}/{phone_name}/{phone_name}_GnssLog.txt\"))\n",
    "    raw_df = gnss_df['Raw']\n",
    "\n",
    "    # epochを合わせる\n",
    "    derived_df = apply_tips1(raw_df, derived_df)\n",
    "    derived_df = apply_tips5(derived_df)\n",
    "    derived_df = derived_df.sort_values('millisSinceGpsEpoch')\n",
    "    \n",
    "    # pseudorangeの修正\n",
    "    derived_df['correctedPrM'] = derived_df.apply(lambda r: r.rawPrM + r.satClkBiasM - r.isrbM - r.ionoDelayM - r.tropoDelayM,axis=1)\n",
    "    \n",
    "    # 伝播時間=擬似距離/光速\n",
    "    # 受信時刻と送信時刻の差分となる\n",
    "    light_speed = 299_792_458\n",
    "    derived_df['transmissionTimeSeconds'] = derived_df['correctedPrM'] / light_speed\n",
    "\n",
    "    # Compute true sat positions at arrival time\n",
    "    # 到着までに衛星位置が移動しているのでこれを補正\n",
    "    omega_e = 7.2921151467e-5\n",
    "    derived_df['xSatPosMRotated'] = \\\n",
    "        np.cos(omega_e * derived_df['transmissionTimeSeconds']) * derived_df['xSatPosM'] \\\n",
    "        + np.sin(omega_e * derived_df['transmissionTimeSeconds']) * derived_df['ySatPosM']\n",
    "\n",
    "    derived_df['ySatPosMRotated'] = \\\n",
    "        - np.sin(omega_e * derived_df['transmissionTimeSeconds']) * derived_df['xSatPosM'] \\\n",
    "        + np.cos(omega_e * derived_df['transmissionTimeSeconds']) * derived_df['ySatPosM']\n",
    "\n",
    "    derived_df['zSatPosMRotated'] = derived_df['zSatPosM']\n",
    "\n",
    "    derived_df['uncertaintyWeight'] = 1 / derived_df['rawPrUncM']\n",
    "\n",
    "    output_df = pd.DataFrame()\n",
    "    d_list = []\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    z_list = []\n",
    "    epoch_list = []\n",
    "    for epoch, df in derived_df.groupby('millisSinceGpsEpoch'): \n",
    "        # Corrected pseudorange according to data instructions\n",
    "        # Time it took for signal to travel\n",
    "        # Start point for the optimiser\n",
    "        N = len([i for i in df[\"signalType\"].unique() if i != \"GPS_L1\"])\n",
    "\n",
    "        # 最小2乗法による座標の推定\n",
    "        # GPS_L1のみの場合、状態数=4\n",
    "        # 非GPS_L1の数に応じて状態数が増える\n",
    "        # x0 = [0]*(4 + N)\n",
    "        x0 = [0]*4\n",
    "\n",
    "        # GPS_L1以外のisrbMの列を作成\n",
    "        # for signal_type in df[\"signalType\"].unique():\n",
    "        #     if signal_type != \"GPS_L1\":\n",
    "        #         df[f\"{signal_type}_isrbM\"] = 0\n",
    "        #         df.loc[df[\"signalType\"]==signal_type, f\"{signal_type}_isrbM\"] = df.loc[df[\"signalType\"]==signal_type, \"isrbM\"].values   \n",
    "\n",
    "        opt_res = opt.least_squares(distance, x0, kwargs=df.to_dict(orient=\"list\"))\n",
    "\n",
    "        # Optimiser yields a position in the ECEF coordinates\n",
    "        opt_res_pos = opt_res.x\n",
    "        d = distance(opt_res_pos, **df.to_dict(orient=\"list\"))\n",
    "\n",
    "        # ECEF position to lat/long\n",
    "        wls_estimated_pos = ecef2lla(*opt_res_pos[:3])\n",
    "        wls_estimated_pos = np.squeeze(wls_estimated_pos)\n",
    "        d_list.append(d)\n",
    "        x_list.append(wls_estimated_pos[0])\n",
    "        y_list.append(wls_estimated_pos[1])\n",
    "        z_list.append(wls_estimated_pos[2])\n",
    "        epoch_list.append(epoch)\n",
    "\n",
    "    output_df[\"latDeg\"] = x_list\n",
    "    output_df[\"lngDeg\"] = y_list\n",
    "    output_df['heightAboveWgs84EllipsoidM'] = z_list\n",
    "    output_df[\"dist\"] = d_list\n",
    "    output_df['millisSinceGpsEpoch'] = epoch_list\n",
    "    output_df['collectionName'] = collection_name\n",
    "    output_df['phoneName'] = phone_name\n",
    "\n",
    "    output_df.to_csv(output_dir + f'{collection_name}_{phone_name}_derived.csv', index=False)\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "import multiprocessing\n",
    "\n",
    "gr = base_train.groupby(['collectionName','phoneName'])\n",
    "processes = multiprocessing.cpu_count()\n",
    "with multiprocessing.Pool(processes=processes) as pool:\n",
    "    dfs = pool.imap_unordered(estimate_train_position_by_derived, gr)\n",
    "    dfs = tqdm(dfs, total=len(gr))\n",
    "    dfs = list(dfs)\n",
    "all_derived_df = pd.concat(dfs).sort_values(['collectionName', 'phoneName', 'millisSinceGpsEpoch']).reset_index(drop=True)     "
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/73 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "92601b27b1004e9aaaf1059802c9bb4e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading ../input/google-smartphone-decimeter-challenge/train/2021-04-28-US-SJC-1/SamsungS20Ultra/SamsungS20Ultra_GnssLog.txt\n",
      "Loading ../input/google-smartphone-decimeter-challenge/train/2021-04-28-US-SJC-1/Pixel4/Pixel4_GnssLog.txt\n",
      "Loading ../input/google-smartphone-decimeter-challenge/train/2021-04-22-US-SJC-1/Pixel4/Pixel4_GnssLog.txt\n",
      "Loading ../input/google-smartphone-decimeter-challenge/train/2021-04-22-US-SJC-1/SamsungS20Ultra/SamsungS20Ultra_GnssLog.txt\n",
      "Loading ../input/google-smartphone-decimeter-challenge/train/2021-04-29-US-SJC-2/SamsungS20Ultra/SamsungS20Ultra_GnssLog.txt\n",
      "Loading ../input/google-smartphone-decimeter-challenge/train/2021-04-29-US-SJC-2/Pixel4/Pixel4_GnssLog.txt\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "from tqdm.notebook import tqdm\n",
    "df_list = []\n",
    "count = 0\n",
    "for (collection_name, phone_name), base_df in tqdm(base_train.groupby(['collectionName','phoneName'])):\n",
    "    # break\n",
    "    if \"SJC\" in collection_name:\n",
    "        print(\"\")\n",
    "        print(collection_name, phone_name)\n",
    "        base_df = base_df.sort_values('millisSinceGpsEpoch')\n",
    "        target_gt = gt[(gt['collectionName']==collection_name)&(gt['phoneName']==phone_name)].sort_values('millisSinceGpsEpoch').reset_index(drop=True)\n",
    "        # 上で作成したderivedデータの読み込み\n",
    "        derived_df = pd.read_csv(output_dir + f'{collection_name}_{phone_name}_derived.csv')\n",
    "        derived_df = derived_df[~derived_df[\"millisSinceGpsEpoch\"].duplicated()].sort_values(\"millisSinceGpsEpoch\").reset_index(drop=True)\n",
    "        derived_df = derived_df.rename(columns={\"latDeg\":\"_latDeg\", \"lngDeg\":\"_lngDeg\"})\n",
    "        print(base_df.shape, target_gt.shape, derived_df.shape)\n",
    "        base_score = get_train_score(base_df, target_gt)\n",
    "        print(\"baseline:\", base_score)\n",
    "\n",
    "        derived_df = pd.merge_asof(base_df, derived_df[[\"millisSinceGpsEpoch\", \"_latDeg\", \"_lngDeg\"]], on=[\"millisSinceGpsEpoch\"], tolerance=10, direction='nearest')\n",
    "\n",
    "        # データが欠損しているところはbaselineで置き換える\n",
    "        derived_df.loc[derived_df[\"_latDeg\"].isna(), \"_latDeg\"] = derived_df.loc[derived_df[\"_latDeg\"].isna(), \"latDeg\"].values\n",
    "        derived_df.loc[derived_df[\"_lngDeg\"].isna(), \"_lngDeg\"] = derived_df.loc[derived_df[\"_lngDeg\"].isna(), \"lngDeg\"].values\n",
    "\n",
    "        derived_df = derived_df.drop([\"latDeg\", \"lngDeg\"], axis=1).rename(columns={\"_latDeg\":\"latDeg\",\"_lngDeg\":\"lngDeg\"})\n",
    "        df_list.append(derived_df)\n",
    "        derived_score = get_train_score(derived_df, target_gt)\n",
    "        print(\"derived:\", derived_score)\n",
    "        # if count == 1:\n",
    "        #     break\n",
    "        # count += 1\n",
    "corrected_base_df = pd.concat(df_list).reset_index(drop=True)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/73 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85d318847f5d471c9a2f26f7032fe1f4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "2021-04-22-US-SJC-1 Pixel4\n",
      "(2890, 10) (2890, 11) (2888, 7)\n",
      "baseline: 24.65997800891282\n",
      "derived: 35.505252266407474\n",
      "\n",
      "2021-04-22-US-SJC-1 SamsungS20Ultra\n",
      "(2826, 10) (2826, 11) (2825, 7)\n",
      "baseline: 17.768175752284254\n",
      "derived: 18.09509395214818\n",
      "\n",
      "2021-04-28-US-SJC-1 Pixel4\n",
      "(2014, 10) (2014, 11) (2011, 7)\n",
      "baseline: 14.370939744208872\n",
      "derived: 25.924177901242086\n",
      "\n",
      "2021-04-28-US-SJC-1 SamsungS20Ultra\n",
      "(2083, 10) (2083, 11) (2081, 7)\n",
      "baseline: 20.17089764148841\n",
      "derived: 19.793631863851548\n",
      "\n",
      "2021-04-29-US-SJC-2 Pixel4\n",
      "(2330, 10) (2330, 11) (2328, 7)\n",
      "baseline: 20.182595805477582\n",
      "derived: 21.52560828172458\n",
      "\n",
      "2021-04-29-US-SJC-2 SamsungS20Ultra\n",
      "(2370, 10) (2370, 11) (2369, 7)\n",
      "baseline: 19.444814738425706\n",
      "derived: 17.852071672964758\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# collection_name = '2021-01-05-US-SVL-1' \n",
    "# phone_name = 'Mi8'\n",
    "# derived_df = pd.read_csv(output_dir + f'{collection_name}_{phone_name}_derived.csv')\n",
    "# base_df = base_train[(base_train['collectionName']==collection_name)&(base_train['phoneName']==phone_name)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import seaborn as sns\n",
    "# sns.scatterplot(y='px', x='millisSinceGpsEpoch', data=derived_df[derived_df['signalType']=='GPS_L1'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import seaborn as sns\n",
    "# sns.scatterplot(y='latDeg', x='millisSinceGpsEpoch', data=base_df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# derived_df['px'].plot('signalType')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "get_train_score(base_train[base_train[\"collectionName\"].str.contains(\"SJC\")], gt)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "get_train_score(corrected_base_df, gt)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}