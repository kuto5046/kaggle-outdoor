{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create dataset \n",
    "\n",
    "v2:lightGBM用delta学習用のデータセットを作成する "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '../input/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def to_pickle(filename, obj):\n",
    "    with open(filename, mode='wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "        \n",
    "def from_pickle(filename):\n",
    "    with open(filename, mode='rb') as f:\n",
    "        obj = pickle.load(f)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1段階目(ホストのコードでtxt2dfする)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_train_dir = root_dir + 'imu_dataset_v0/train/'\n",
    "os.makedirs(output_train_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_test_dir = root_dir + 'imu_dataset_v0/test/'\n",
    "os.makedirs(output_test_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gnss_log_to_dataframes(path):\n",
    "    # print('\\nLoading ' + path, flush=True)\n",
    "    gnss_section_names = {'Raw','UncalAccel', 'UncalGyro', 'UncalMag', 'Fix', 'Status', 'OrientationDeg'}\n",
    "    with open(path) as f_open:\n",
    "        datalines = f_open.readlines()\n",
    "\n",
    "    datas = {k: [] for k in gnss_section_names}\n",
    "    gnss_map = {k: [] for k in gnss_section_names}\n",
    "    for i, dataline in enumerate(datalines):\n",
    "        is_header = dataline.startswith('#')\n",
    "        dataline = dataline.strip('#').strip().split(',')\n",
    "        # skip over notes, version numbers, etc\n",
    "        if is_header and dataline[0] in gnss_section_names:\n",
    "            gnss_map[dataline[0]] = dataline[1:]\n",
    "        elif not is_header:\n",
    "            datas[dataline[0]].append(dataline[1:])\n",
    "    \n",
    "    results = dict()\n",
    "    for k, v in datas.items():\n",
    "        results[k] = pd.DataFrame(v, columns=gnss_map[k])\n",
    "    # pandas doesn't properly infer types from these lists by default\n",
    "    for k, df in results.items():\n",
    "        for col in df.columns:\n",
    "            if col == 'CodeType':\n",
    "                continue\n",
    "            results[k][col] = pd.to_numeric(results[k][col])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_name(df, collection_name, phone_name):\n",
    "    df['collectionName'] = collection_name\n",
    "    df['phoneName'] = phone_name\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_imu_base_dataset(path):\n",
    "    raw_df = pd.DataFrame()\n",
    "    acc_df = pd.DataFrame()\n",
    "    gyro_df = pd.DataFrame()\n",
    "    mag_df = pd.DataFrame()\n",
    "    fix_df = pd.DataFrame()\n",
    "    status_df = pd.DataFrame()\n",
    "    orient_df = pd.DataFrame()\n",
    "\n",
    "    collection_name = path.split('/')[3]\n",
    "    phone_name = path.split('/')[4]\n",
    "\n",
    "    # get GnssLog file \n",
    "    for file_path in glob.glob(os.path.join(path, f\"{phone_name}_GnssLog.txt\")):\n",
    "        result_dict = gnss_log_to_dataframes(file_path)\n",
    "        raw_df  = pd.concat([raw_df, result_dict['Raw']])\n",
    "        acc_df  = pd.concat([acc_df, result_dict['UncalAccel']])\n",
    "        gyro_df  = pd.concat([gyro_df, result_dict['UncalGyro']])\n",
    "        mag_df  = pd.concat([mag_df, result_dict['UncalMag']])\n",
    "        fix_df  = pd.concat([fix_df, result_dict['Fix']])\n",
    "        status_df  = pd.concat([status_df, result_dict['Status']])\n",
    "        orient_df  = pd.concat([orient_df, result_dict['OrientationDeg']])\n",
    "    \n",
    "    raw_df = add_name(raw_df, collection_name, phone_name)\n",
    "    acc_df = add_name(acc_df, collection_name, phone_name)\n",
    "    gyro_df = add_name(gyro_df, collection_name, phone_name)\n",
    "    mag_df = add_name(mag_df, collection_name, phone_name)\n",
    "    fix_df = add_name(fix_df, collection_name, phone_name)\n",
    "    status_df = add_name(status_df, collection_name, phone_name)\n",
    "    orient_df = add_name(orient_df, collection_name, phone_name)\n",
    "\n",
    "    return (raw_df, acc_df, gyro_df, mag_df, fix_df, status_df, orient_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de26253b06de49dea1321cc8df909b13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee47293b37ea4ea9b38d341a3bc00562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train\n",
    "import multiprocessing\n",
    "processes = multiprocessing.cpu_count()\n",
    "with multiprocessing.Pool(processes=processes) as pool:\n",
    "    path_list = glob.glob(os.path.join(root_dir, 'train/*/*'), recursive=True)\n",
    "    results = pool.imap_unordered(create_imu_base_dataset, path_list)\n",
    "    results = list(tqdm(results, total=len(path_list)))\n",
    "\n",
    "\n",
    "all_raw_df = pd.DataFrame()\n",
    "all_acc_df = pd.DataFrame()\n",
    "all_gyro_df = pd.DataFrame()\n",
    "all_mag_df = pd.DataFrame()\n",
    "all_fix_df = pd.DataFrame()\n",
    "all_status_df = pd.DataFrame()\n",
    "all_orient_df = pd.DataFrame()\n",
    "\n",
    "for result in tqdm(results):\n",
    "    raw_df, acc_df, gyro_df, mag_df, fix_df, status_df, orient_df = result\n",
    "    all_raw_df = pd.concat([all_raw_df, raw_df]).reset_index(drop=True)\n",
    "    all_acc_df = pd.concat([all_acc_df, acc_df]).reset_index(drop=True)\n",
    "    all_gyro_df = pd.concat([all_gyro_df, gyro_df]).reset_index(drop=True)\n",
    "    all_mag_df = pd.concat([all_mag_df, mag_df]).reset_index(drop=True)\n",
    "    all_fix_df = pd.concat([all_fix_df, fix_df]).reset_index(drop=True)\n",
    "    all_status_df = pd.concat([all_status_df, status_df]).reset_index(drop=True)\n",
    "    all_orient_df = pd.concat([all_orient_df, orient_df]).reset_index(drop=True)\n",
    "\n",
    "to_pickle(output_train_dir + 'raw.pkl', all_raw_df)\n",
    "to_pickle(output_train_dir + 'acc.pkl', all_acc_df)\n",
    "to_pickle(output_train_dir + 'gyro.pkl', all_gyro_df)\n",
    "to_pickle(output_train_dir + 'mag.pkl', all_mag_df)\n",
    "to_pickle(output_train_dir + 'fix.pkl', all_fix_df)\n",
    "to_pickle(output_train_dir + 'status.pkl', all_status_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a53fd6d5e712459f9b2cfe308458de12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d84b3a0f2a7d456f88a0f7213cec5fab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test\n",
    "import multiprocessing\n",
    "processes = multiprocessing.cpu_count()\n",
    "with multiprocessing.Pool(processes=processes) as pool:\n",
    "    path_list = glob.glob(os.path.join(root_dir, 'test/*/*'), recursive=True)\n",
    "    results = pool.imap_unordered(create_imu_base_dataset, path_list)\n",
    "    results = list(tqdm(results, total=len(path_list)))\n",
    "\n",
    "\n",
    "all_raw_df = pd.DataFrame()\n",
    "all_acc_df = pd.DataFrame()\n",
    "all_gyro_df = pd.DataFrame()\n",
    "all_mag_df = pd.DataFrame()\n",
    "all_fix_df = pd.DataFrame()\n",
    "all_status_df = pd.DataFrame()\n",
    "all_orient_df = pd.DataFrame()\n",
    "\n",
    "for result in tqdm(results):\n",
    "    raw_df, acc_df, gyro_df, mag_df, fix_df, status_df, orient_df = result\n",
    "    all_raw_df = pd.concat([all_raw_df, raw_df]).reset_index(drop=True)\n",
    "    all_acc_df = pd.concat([all_acc_df, acc_df]).reset_index(drop=True)\n",
    "    all_gyro_df = pd.concat([all_gyro_df, gyro_df]).reset_index(drop=True)\n",
    "    all_mag_df = pd.concat([all_mag_df, mag_df]).reset_index(drop=True)\n",
    "    all_fix_df = pd.concat([all_fix_df, fix_df]).reset_index(drop=True)\n",
    "    all_status_df = pd.concat([all_status_df, status_df]).reset_index(drop=True)\n",
    "    all_orient_df = pd.concat([all_orient_df, orient_df]).reset_index(drop=True)\n",
    "\n",
    "to_pickle(output_test_dir + 'raw.pkl', all_raw_df)\n",
    "to_pickle(output_test_dir + 'acc.pkl', all_acc_df)\n",
    "to_pickle(output_test_dir + 'gyro.pkl', all_gyro_df)\n",
    "to_pickle(output_test_dir + 'mag.pkl', all_mag_df)\n",
    "to_pickle(output_test_dir + 'fix.pkl', all_fix_df)\n",
    "to_pickle(output_test_dir + 'status.pkl', all_status_df)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 5
}