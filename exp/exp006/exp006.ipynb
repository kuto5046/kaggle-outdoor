{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ground_truth(args):\n",
    "    (collectionName, phoneName), df = args\n",
    "    \n",
    "    path = root_dir / f\"train/{collectionName}/{phoneName}/ground_truth.csv\"\n",
    "    target_df = pd.read_csv(path)\n",
    "    output_df = pd.DataFrame()\n",
    "    # merge derived and target by 'millisSinceGpsEpoch'\n",
    "    for epoch, epoch_df in df.groupby('millisSinceGpsEpoch'):\n",
    "        idx = (target_df['millisSinceGpsEpoch'] - epoch).abs().argmin()\n",
    "        epoch_diff = epoch - target_df.loc[idx, 'millisSinceGpsEpoch']\n",
    "        epoch_df['epoch_diff'] = epoch_diff\n",
    "        epoch_df['target_latDeg'] = target_df.loc[idx, 'latDeg']\n",
    "        epoch_df['target_lngDeg'] = target_df.loc[idx, 'lngDeg']\n",
    "        output_df = pd.concat([output_df, epoch_df]).reset_index(drop=True)    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def visualize_trafic(df):\n",
    "    fig = px.scatter_mapbox(df,\n",
    "                            \n",
    "                            # Here, plotly gets, (x,y) coordinates\n",
    "                            lat=\"latDeg\",\n",
    "                            lon=\"lngDeg\",\n",
    "                            text='phoneName',\n",
    "                            \n",
    "                            #Here, plotly detects color of series\n",
    "                            color=\"collectionName\",\n",
    "                            labels=\"collectionName\",\n",
    "                            \n",
    "                            zoom=9,\n",
    "                            center={\"lat\":37.423576, \"lon\":-122.094132},\n",
    "                            height=600,\n",
    "                            width=800)\n",
    "    fig.update_layout(mapbox_style='stamen-terrain')\n",
    "    fig.update_layout(margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0})\n",
    "    fig.update_layout(title_text=\"GPS trafic\")\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def visualize_collection(df, collection_name='2021-04-29-US-SJC-2'):\n",
    "    gt_df = pd.read_csv('../../input/all_ground_truth.csv')\n",
    "    gt_df['phoneName'] = 'ground truth'\n",
    "    gt_df = pd.concat([df, gt_df])\n",
    "    fig = px.scatter_mapbox(gt_df[gt_df['collectionName']==collection_name],\n",
    "                                \n",
    "                            # Here, plotly gets, (x,y) coordinates\n",
    "                            lat=\"latDeg\",\n",
    "                            lon=\"lngDeg\",\n",
    "                                \n",
    "                            #Here, plotly detects color of series\n",
    "                            color=\"phoneName\",\n",
    "                            labels=\"phoneName\",\n",
    "                                \n",
    "                            zoom=9,\n",
    "                            center={\"lat\":37.423576, \"lon\":-122.094132},\n",
    "                            height=600,\n",
    "                            width=800)\n",
    "    fig.update_layout(mapbox_style='stamen-terrain')\n",
    "    fig.update_layout(margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0})\n",
    "    fig.update_layout(title_text=\"GPS trafic\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric\n",
    "def calc_haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Calculates the great circle distance between two points\n",
    "    on the earth. Inputs are array-like and specified in decimal degrees.\n",
    "    \"\"\"\n",
    "    RADIUS = 6_367_000\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + \\\n",
    "        np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    dist = 2 * RADIUS * np.arcsin(a**0.5)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simdkalman\n",
    "\n",
    "# define kf model\n",
    "T = 1.0\n",
    "state_transition = np.array([[1, 0, T, 0, 0.5 * T ** 2, 0], [0, 1, 0, T, 0, 0.5 * T ** 2], [0, 0, 1, 0, T, 0],\n",
    "                             [0, 0, 0, 1, 0, T], [0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 1]])\n",
    "process_noise = np.diag([1e-5, 1e-5, 5e-6, 5e-6, 1e-6, 1e-6]) + np.ones((6, 6)) * 1e-9\n",
    "observation_model = np.array([[1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0]])\n",
    "observation_noise = np.diag([5e-5, 5e-5]) + np.ones((2, 2)) * 1e-9\n",
    "\n",
    "kf = simdkalman.KalmanFilter(\n",
    "        state_transition = state_transition,\n",
    "        process_noise = process_noise,\n",
    "        observation_model = observation_model,\n",
    "        observation_noise = observation_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_kf_smoothing(df, kf_=kf):\n",
    "    unique_paths = df[['collectionName', 'phoneName']].drop_duplicates().to_numpy()\n",
    "    for collection, phone in tqdm(unique_paths):\n",
    "        cond = np.logical_and(df['collectionName'] == collection, df['phoneName'] == phone)\n",
    "        data = df[cond][['latDeg', 'lngDeg']].to_numpy()\n",
    "        data = data.reshape(1, len(data), 2)\n",
    "        smoothed = kf_.smooth(data)\n",
    "        df.loc[cond, 'latDeg'] = smoothed.states.mean[0, :, 0]\n",
    "        df.loc[cond, 'lngDeg'] = smoothed.states.mean[0, :, 1]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_interpolation(input_df):\n",
    "    dfs = pd.DataFrame()\n",
    "    for (collectionName, phoneName), df in input_df.groupby(['collectionName','phoneName']):\n",
    "\n",
    "        df['delta'] = calc_haversine(df['latDeg'], df['lngDeg'], df['latDeg'].shift(1), df['lngDeg'].shift(1))\n",
    "        df['time_delta'] = df['millisSinceGpsEpoch'] - df['millisSinceGpsEpoch'].shift(1)\n",
    "        df['delta'].fillna(0, inplace=True)\n",
    "        df['time_delta'].fillna(0, inplace=True)\n",
    "        df['speed'] = df['delta'] / (df['time_delta']/1000)  # m/s\n",
    "        df['speed'].fillna(0, inplace=True)\n",
    "\n",
    "        # 一度欠損値にする\n",
    "        df.loc[50<df['speed'], ['latDeg', 'lngDeg']] = np.nan\n",
    "        df['dummy_datetime'] = pd.to_datetime(df['millisSinceGpsEpoch'])\n",
    "        df = df.set_index('dummy_datetime')\n",
    "\n",
    "        # 時間に合わせて線形補間\n",
    "        df = df.interpolate(method='time').reset_index(drop=True)\n",
    "        dfs = pd.concat([dfs, df]).reset_index(drop=True)\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "EXP_NAME = str(Path().resolve()).split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# waypointを補正したdataset\n",
    "root_dir = Path('../../input/')\n",
    "test_df = pd.read_csv(root_dir / \"baseline_locations_test.csv\")\n",
    "sub_df = pd.read_csv(root_dir / 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LI -> KF  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "train_df = pd.read_csv(root_dir / \"baseline_locations_train.csv\")\n",
    "processes = multiprocessing.cpu_count()\n",
    "with multiprocessing.Pool(processes=processes) as pool:\n",
    "    gr = train_df.groupby(['collectionName','phoneName'])\n",
    "    dfs = pool.imap_unordered(get_ground_truth, gr)\n",
    "    dfs = tqdm(dfs, total=len(gr))\n",
    "    dfs = list(dfs)\n",
    "train_df = pd.concat(dfs).sort_values(['collectionName', 'phoneName', 'millisSinceGpsEpoch'])\n",
    "calc_haversine(train_df['latDeg'],train_df['lngDeg'],train_df['target_latDeg'], train_df['target_lngDeg']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_collection(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = linear_interpolation(train_df)\n",
    "calc_haversine(train_df['latDeg'],train_df['lngDeg'],train_df['target_latDeg'], train_df['target_lngDeg']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_collection(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stopping_group(a, n=5):\n",
    "    rle = [[a[0], 1]]\n",
    "\n",
    "    for elem in a[1: ]:\n",
    "        if rle[-1][0] == elem:\n",
    "            rle[-1][1] += 1\n",
    "        else:\n",
    "            rle.append([elem, 1])\n",
    "    id = 1\n",
    "    result = []\n",
    "    for elem, cnt in rle:\n",
    "        if elem == 1 and cnt >= n:\n",
    "            result += [id] * cnt\n",
    "            id += 1\n",
    "        else:\n",
    "            result += [0] * cnt\n",
    "    return result\n",
    "\n",
    "\n",
    "def apply_stopping_pp(input_df, speed_thr=1, cont_thr=5):\n",
    "    # 速度が1m/s以下のものは停止しているとみなしてその近い時間で平均を取る\n",
    "    input_df['is_stopping'] = 0\n",
    "    input_df.loc[train_df['speed']<speed_thr, 'is_stopping'] = 1\n",
    "\n",
    "    coll_df_list = []\n",
    "    for collection_name, coll_df in input_df.groupby('collectionName'):\n",
    "        a = coll_df.sort_values('millisSinceGpsEpoch')['is_stopping'].to_numpy()\n",
    "        coll_df[\"stopping_group\"] = get_stopping_group(a, n=cont_thr)\n",
    "        stopping_point_df = coll_df[coll_df[\"stopping_group\"]!=0].groupby(\"stopping_group\")[[\"latDeg\", \"lngDeg\"]].mean().reset_index()\n",
    "\n",
    "        for i, row in stopping_point_df.iterrows():\n",
    "            coll_df.loc[coll_df[\"stopping_group\"]==row[\"stopping_group\"], \"latDeg\"] = row[\"latDeg\"]\n",
    "            coll_df.loc[coll_df[\"stopping_group\"]==row[\"stopping_group\"], \"lngDeg\"] = row[\"lngDeg\"]\n",
    "        coll_df_list.append(coll_df)\n",
    "\n",
    "    output_df = pd.concat(coll_df_list).reset_index(drop=True)\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_train_df = apply_stopping_pp(train_df, speed_thr=1, cont_thr=10)\n",
    "calc_haversine(_train_df['latDeg'],_train_df['lngDeg'],_train_df['target_latDeg'], _train_df['target_lngDeg']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_collection(_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = apply_kf_smoothing(train_df)\n",
    "calc_haversine(train_df['latDeg'],train_df['lngDeg'],train_df['target_latDeg'], train_df['target_lngDeg']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_collection(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 同じcollection、epochである端末の予測値を平均する(アンサンブル的な感じ)\n",
    "train_df = train_df.merge(train_df.groupby(['collectionName', 'millisSinceGpsEpoch'])[['latDeg', 'lngDeg']].mean(), on=['collectionName', 'millisSinceGpsEpoch'])\n",
    "train_df = train_df.drop(['latDeg_x', 'lngDeg_x'], axis=1).rename(columns={'latDeg_y':'latDeg', 'lngDeg_y':'lngDeg'})\n",
    "\n",
    "calc_haversine(train_df['latDeg'],train_df['lngDeg'],train_df['target_latDeg'], train_df['target_lngDeg']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = linear_interpolation(train_df)\n",
    "calc_haversine(train_df['latDeg'],train_df['lngDeg'],train_df['target_latDeg'], train_df['target_lngDeg']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def to_pickle(filename, obj):\n",
    "    with open(filename, mode='wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "        \n",
    "def from_pickle(filename):\n",
    "    with open(filename, mode='rb') as f:\n",
    "        obj = pickle.load(f)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = linear_interpolation(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = apply_kf_smoothing(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 同じcollection、epochである端末の予測値を平均する(アンサンブル的な感じ)\n",
    "test_df = test_df.merge(test_df.groupby(['collectionName', 'millisSinceGpsEpoch'])[['latDeg', 'lngDeg']].mean(), on=['collectionName', 'millisSinceGpsEpoch'])\n",
    "test_df = test_df.drop(['latDeg_x', 'lngDeg_x'], axis=1).rename(columns={'latDeg_y':'latDeg', 'lngDeg_y':'lngDeg'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = apply_stopping_pp(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_df = sub_df.assign(\n",
    "#     latDeg = test_df['latDeg'],\n",
    "#     lngDeg = test_df['lngDeg']\n",
    "# )\n",
    "sub_df = sub_df.drop(['latDeg', 'lngDeg'], axis=1).merge(test_df[['phone', 'millisSinceGpsEpoch', 'latDeg', 'lngDeg']], on=['phone', 'millisSinceGpsEpoch'])\n",
    "sub_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_sub_df = pd.read_csv('../exp002/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_haversine(sub_df['latDeg'],sub_df['lngDeg'],\n",
    "               _sub_df['latDeg'], _sub_df['lngDeg']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 5
}